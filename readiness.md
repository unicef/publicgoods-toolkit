# Open Source Readiness

**KEY RECOMMENDATION**: The path to building organizational capacity to execute well on an open source DPG can roughly follow 'readiness models' developed through experience in private industry. Consider starting with skill-building experiments in places where your lack of open source investment are causing problems (e.g. lack of re-usability) that could be addressed by relatively small-scale, lower-risk investments.  

**KEY RECOMMENDATION**: Cost/benefit analyses and valuation frameworks
can be useful and necessary tools in building a case for an open approach, but they don’t capture
the full value of open source investments.  Be sure to include areas of 'adjacent value' when assessing and reporting on the overall value of your DPG. These can be multipliers to your project's valuation.

EXAMPLE: The [GeoNode project](https://geonode.org/), initiated by the World Bank's Global Facility for Disaster Reduction and Recovery (GFDDR), realized significant but difficult-to-quantify value through the vibrant commercial community that grew around the project. In time, these contributors became so active and financially committed to the project's continued development that [GFDDR was able to scale back its investment](https://opendri.org/wp-content/uploads/2017/03/OpenDRI-and-GeoNode-a-Case-Study-on-Institutional-Investments-in-Open-Source.pdf). 

Open source is all about execution.  Reaping the benefits of open
source investment requires completing a series of difficult steps
ranging from designing an initial strategy to building an appropriate
community to leveraging the resulting dynamics for strategic
advantage, whether that be scaling to broad adoption quickly or orchestrating participants to focus on areas of needed innovation. This module presents a somewhat abstract but experiential
based view of organizational readiness, including models to consider
referencing, and practical advice for how to move your team along the
path to masterful open source execution.  The Adoptability module (TBD
LINK) delves more deeply into specific open source capabilities you'll
need to effectively adopt or build an open source product.

Most government teams are not yet prepared to travel this capability
path and reap those rewards at scale.  They lag in their ability to
execute, largely because they don't have enough experience,
particularly as compared to private industry.  But governments can
learn quickly from what's been tried and tested by others as they've
built their organizational capacity to use open source development to
its full potential.

As an agency starts to climb the learning curve, it can be helpful to
assess current abilities as a form of organizational readiness and to
describe the journey to mastery as one of gaining capability.  To do
that, we might locate current capabilities in a readiness model.
These clarify where an agency is in its journey to mastery and suggest
next steps and likely results.  Often, teams use these models to
identify areas for potential growth as well as potential pitfalls.
They are most useful for those early in their open source progress,
and this module focuses on those beginning stages.

It is useful for an agency to consider its maturity on an organization
wide basis, but creation of an open source DPG is usually executed by
teams, and it is the capabilities of specific teams that matter most.
Therefore, this module considers individual teams as the starting
point for analysis, because even agency-wide open source skills
training will succeed or fail mostly at the level of specific teams
working on specific projects.  However, teams obviously work within an
organization that shapes their operational environment, and at some
point the broader the organizational view matters.  When and under
what conditions this occurs is very case dependent.

There are several readiness models that go by various names.
Practitioners often describe climbing the "readiness ladder".  We
share a number of them here because it is often worth considering more
than one when examining an organization or a particular team.

* [Jeff McAffer's Engagement Model](https://mcaffer.com/2019/02/Open-source-engagement)
 
* [TODO Group model](https://github.com/todogroup/ospo101/blob/main/module2/README.md#climbing-the-open-source-ladder)

* [GitHub's Maturity Model](https://github.com/github/maturity-model)

* [Qalipso's Model](https://en.wikipedia.org/wiki/OpenSource_Maturity_Model)

* [Stephen Walli's Maturation Toward Adulthood](https://opensource.com/life/15/4/what-does-an-adult-look-like-in-an-open-source-community)

* [FinOS Open Source Ladder](https://www.finos.org/hubfs/FINOS/website/pages/community/Open%20Source%20Readiness%20Roadmap%20-%203.10.2018.png)

Of the published models, we find the first one -- written by Microsoft
Senior Director Jeff McAffer (now Senior Director at GitHub)-- is
particularly useful.  It's simple but includes strategic components,
accounts for realistic failure modes, and understands that open source
readiness will be unevenly distributed in any agency large enough to
have multiple teams.  We also like how it describes the phases of
capability growth almost like generalized ‘mental models’ at an
organization or team level in a way that's both abstract and
pragmatic.  We've found that stepping back every so often to reflect
using such shared language and concepts helps teams stay grounded in
the big picture, rather than focusing exclusively on the details.

**RECOMMENDATION**: Engage the team in a frank discussion about
your open source readiness and locate the team and the organization on
McAffer's engagement model.  What might this level mean for
opportunities for growth, what might it mean for potential problems?
Identify three key steps the people in that discussion can take to
improve execuation capabilities at the team level and keep checking in
as the team develops.

On many teams, initial open source capabilities might be nascent.
Most team members have not had significant (or perhaps even any)
experience using open source strategies to create value.  The team
works in an environment where FOSS investment is rare, and many do not
see much reason to change that.  That lack of knowledge might
translate in some quarters into hostility toward FOSS.  People will
say "It can never work here" even as open source slowly seeps into
more and more of the technology around them.

At this stage, open source strategies will be difficult to execute.
Internal political risks might be high.  Policies needed to engage
open source productively might be missing.  Staff might not know how
to begin working with external open source contributors.  Many people
might lack even a basic understanding of what it means to do open
source work.  Efforts to work in an open source mode suffer from an
increased risk of failure, and they might fail in ways that reinforce
the belief that open source is not worth further consideration.

Many factors might move a team past this early stage and on their way
toward tolerating open source, but movement usually comes from
external pressure, changing environments, and staff additions and
turnover.  As conditions around an agency begin to change, and the
costs and risks of refusing to engage start to rise, pressure to
engage open source will increase.

Those costs might include the pain of maintaining internal forks of
external open source projects. Or more commonly, the risks of *not*
maintaining all those forks.  Similarly, the benefits of making minor
open source investments start to become clear, even if only because
other teams will begin to reap those benefits and your team gains
good, internal examples to follow.

However any specific team begins to adapt, climbing the learning curve
is often an exercise in experimentation.  Most don't think of open
source investment in those terms.  Instead, they cast initial open
source forays as making small concessions to necessity.  Some see
these experiments as seizing unique, non-repeatable advantages.  Most
don't think of those small, initial projects as the future direction
of the team.  More teams should consider the possibility, though.
Sometimes, explicitly labeling such experiments as learning exercises
and skill-building allows a team to maximize the value of those
experimental investments.  It prioritizes reflective analysis and
learning.  It gives permission to fail.  Those can be useful to teams
seeking adaptability.  When considering McAffer's model, we might
relabel his "tolerance" phase as "experimentation".

**KEY RECOMMENDATION**: Look for the places where your lack of open
source investment are causing problems that can be addressed by
small-scale, low-risk, experimental engagement. Start there, being sure to label these
experiments as skill-building exercises. Think about how you can
engage your larger team or organization as you develop, making the
learning relevant to their own needs and goals and bringing them along
as allies.

Experiments come in many forms, but the most common first experiment
is using some outside open source code and engaging the open source
project.  That might involve filing bug reports, offering a
contribution, or merely participating in project mailing lists and
forums.  These are all relatively low-risk, low-investment ways to
begin connecting a team to outside FOSS projects.  If your team's
future plans include larger-scale open source engagement, building
skills through these kinds of small-scale experiments can be very
productive.

The experimentation phase is usually a skill-building and
knowledge-gaining phase because it exercises the skills that cause a
team to shift from merely tolerating open source to trying to harness
it.  Having those skills throughout a team provides the vision that
starts to shift attitudes at more than just an individual level.

The problem that arises, especially as multiple teams start to embrace
FOSS, is that they lack the infrastructure to succeed at it across the
entire organization.  They are missing policies, auditing, skills,
culture, and experience.  This is a pivotal, risky moment.  A large
number of teams will still be in the initial phases.  Efforts to move
internal culture toward open source will be perceived by some as a
pointless shift toward the latest buzzword.  Despite your best
attempts to share learning across the organization, experimental
skills will still be unevenly distributed internally.  Many new open
source projects will fail, and this will convince some that all open
source is destined to fail.  The proverbial 'trough of
disillusionment' will seem unbridgable.  In some agencies, some might
even sabotage open source projects for policy or political reasons.

McAffer sees this phase as one of hype, and perhaps that's because
it's also when an agency embraces open source without quite being
ready to execute.  Agencies in this phase tend to engage FOSS in
shallow, unsophisticated ways simply because they don't yet have the
experience to make better strategic use of open source opportunities. 
The way to move past this stage is not to reduce the hype (though that
might help) but rather to increase readiness.

When an agency reaches this stage, it will have multiple teams eager
to do open source and multiple teams still wary of the change.
Managers at this stage will need guidance on using FOSS as a strategic
component and managing teams with increasingly external deliverables.
Developers will need technical infrastructure, easy-to-follow
licensing policies, and permission to engage externally.  Perhaps more
importantly, they will need to develop new habits of working in the
open and sharing even early, rough versions of their work.  Beyond
just technical teams, Human Resources will need hiring and
compensation guidance as both skills and performance evaluation
criteria shift.  Building internal systems that provide all of those
pieces is how agencies gain proficiency.  Adding skills, process, and
policy is how that happens, and it requires management approval and
resources.  Agencies that fail to provide this support from fairly
high in the organization tend to level off at this level of readiness.

**RECOMMENDATION**: If you've been tracking your team's growth in
execution capabilities and bringing others along on your learning
journey, you should have a good *shared* understanding of what skills,
processes and policies you need to execute successfully, along with
proof points of the value such investments will bring.  (Remember that
these skills can come from external vendors and the need to build
local talent, as mentioned throughout this paper).  This will help you
present a strong recommendation to your organization's leadership and
help you move from the Hype to Proficient stage in McAffer's readiness
model.

Another consideration for agencies climbing the readiness ladder is
that the need for skilled open source practitioners will almost always
exceed the supply.  The demand for open source skills is growing so
fast, the world does not have enough experienced open source
strategists and developers to keep up.  A number of companies and
universities have decided to address this problem by centralizing much
of their open source expertise in an Open Source Programs Office
(OSPO).  The OSPO's job is to use that collected expertise to improve
open source readiness and efficacy across the entire organization,
often managing common issues like license compliance, developing an
open source culuture, ensuring high quality code releases, and
advising on software tools.  The Linux Foundation provides a good
[overview of the role and value of
OSPOs](https://www.linuxfoundation.org/resources/open-source-guides/creating-an-open-source-program/).  The
[TODO Group](https://todogroup.org/) is collection of private industry
OSPOs that also provides open guidance and resources.

We are not aware of many agencies that have an OSPO, but governments
should consider focusing open source readiness efforts on one agency
or department that can then help others.  In the United States, the
federal government's General Services Administration (GSA) did this
with [18F](https://18f.gsa.gov/), which, after reaching relatively
high levels of open source capability and knowledge, developed
guidance for other agencies approaching open source.  GSA's Code.gov
has created a
[toolkit](https://github.com/GSA/code-gov-open-source-toolkit) that gives agencies 
guidance around creating and maintaining federal source code inventories and open source repositories.



**RECOMMENDATION** At the organizational level, Open Source
Program Offices can help teams work more effectively and efficiently
in open source.  As you move up the readiness ladder, consider if such
a centralized operational function would help the organization to
execute better.

A final note on understanding and communicating the value or cost-effectiveness of open
source.  Gaining a more sophisticated understanding of this value -
and having that understanding more broadly shared across an
organization and its supporters - is both a prerequisite to and a marker of moving along
these readiness models. Moreover, organizational decision makers and funders will want to know
the cost/benefit ratio or the return on their investment and might also want to
compare the approach to alternatives. 

Ultimately, the value of your DPG will depend upon how well you’ve met
your goals: a qualitative and quantitative assessment of the DPG’s
positive impact on people’s lives.  How you’ll first estimate and later actually measure this social impact is one of the first items to define in your project -- this obviously goes hand-in-hand with goal setting -- and the certainty of your measurements should improve with time. 

There are tools out there that can help you make some cost and benefit determinations, but none capture the full value of an open approach -- especially specific to your context -- and it’s likely that you'll need to modify some combination of these tools to your needs. Start from a holistic view of your project and map out potential benefits and related costs, being realistic about what you can actually measure and prioritizing what will have the most cost and/or the most benefit per the goals of your project. Not everything is relevant. See the Grameen Foundation's ROI analysis framework below for a good example of a thoughtfully bounded approach that's specific to their audience.

The Digital Impact Alliance publishes a great overview of five different
ways of valuing the impact of ICT investments, [A Valuing Impact Toolkit for ICT
Investment](https://digitalimpactalliance.org/wp-content/uploads/2020/10/ICT4D-toolkit.pdf), that includes guidance
on which might be most fitting, depending on factors such as available
resources, skills and data -- important considerations for any organization but perhaps particularly for those in low-resource environments.

To get much deeper into the cost assessment side of software, USAID has published the
[Software Global Goods Valuation Framework](https://www.usaid.gov/cii/software-global-goods-valuation-framework) (with an accompanying spreadsheet) to
assess cumulative development costs through an analysis of both retrospective
and ongoing costs.  Although aimed at digital health products, it fits
other application areas as well.  Perhaps most interesting to this model is its
inclusion of a method for analyzing the cost of code, called the
Constructive Cost Model (COCOMO 81).

For an example of how the World Bank measured the fiscal (not social) impact of
Estonia's X-road(™) project (a post facto measure), see [Estonian
e-Government Ecosystem: Foundation, Applications,
Outcomes](https://thedocs.worldbank.org/en/doc/165711456838073531-0050022016/original/WDR16BPEstonianeGovecosystemVassil.pdf),
which extrapolates a narrow view of fiscal value from the number of
queries made to the system. 

The Grameen Foundation published an [in-depth financial ROI framework](https://mifos.org/blog/documenting-technology-impact-mifos-roi-model-case-studies/) to help microfinance institutions (MFIs) forecast and analyze the benefits of adopting [Mifos](https://mifos.org/), the open source platform for microfinance. It highlights that the decision to adopt and deploy Mifos cannot be based only on the ROI analysis, noting the importance of understanding non-financial intangibles, like creating a better foundation for future innovation. The framework doesn't include these intangible, which can have different prioritization and value across implementations.

Despite that limitation -- and the fact that the framework is unique to Mifos and MFIs and thus isn't an exact model for other projects to follow -- it's a well reasoned approach to a broader view of benefits (categorized as increased revenues and decreased costs specific to how MFIs function) and costs (categorized as project expenses, like data migration and staff time) that's worth reviewing. For those looking to create a DPG with the goal of broad adoption across different locales with slightly different contexts, it's worth studying how the Grameen Foundation created this tool to help MFIs more effectively adopt their DPG.

Again, none of the above models quantify and incorporate the value of the intangible benefits of open source very well, although their costs are generally captured.

The World Bank’s [Open Data for Resilience Initiative & GeoNode:A Case
Study in Institutional Investments in Open
Source](https://opendri.org/wp-content/uploads/2017/03/OpenDRI-and-GeoNode-a-Case-Study-on-Institutional-Investments-in-Open-Source.pdf
) tries to bring in some intangibles in cost and valuation in a slightly more effective way.
Although it’s hard to distill the approach taken in the paper into a
formal framework, it can be described as paying attention to areas of
adjacent value.  This approach aligns pretty naturally with
thinking of an open source project as part of an ecosystem, which will likely be the case for most DPGs that aim for broad social impact.

Looking only at the cost of writing code themselves versus the value
received from sharing costs with partners, it’s estimated that the
GeoNode project brought around a 200% return on investment (as of
2017).  But the real value of open source development to the World Bank's Global
Facility for Disaster Reduction and Recovery (GFDRR), the leading
organization behind GeoNode, was the self-sustaining open source
GeoNode community that emerged and the benefits that community
continues to deliver.  For example, a consortium of U.S. government
agencies quickly picked up development work on the core of GeoNode -- valued at over $1
million USD -- which permitted GFDRR to tune its resource investments to
features it specifically needed.  Companies began providing commercial
support, helping to grow further investment in GeoNode.  A growing
user base made it easier to identify and prioritize areas for
improvement.  These are several of many aspects of GeoNode's community
and ecosystem that prove there's greater value in open source than
what's captured in existing valuation frameworks.


**KEY RECOMMENDATION**: Cost/benefit analyses and valuation frameworks
can be useful and necessary tools, but remember that they don’t capture
the full value of open source investments.  Be sure to include areas
of 'adjacent value' when assessing the overall value of your DPG.
These can be multipliers to your project's valuation.

All of the above describes a path from the very beginning toward
eventual mastery of open source.  Our discussion focused on readiness
in terms of skills and capabilities, but the truth is that doing open
source well is more of a cultural shift than anything
else. Organizations using open source fluently quickly find that the
open approach is just their default process.  That culture shift is
what lies at the top of the readiness learning curve.
